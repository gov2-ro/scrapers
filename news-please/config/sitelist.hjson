# This is a HJSON-File, so comments and so on can be used! See https://hjson.org/
# Furthermore this is first of all the actual config file, but as default just filled with examples.
{
  # Every URL has to be in an array-object in "base_urls".
  # The same URL in combination with the same crawler may only appear once in this array.
  "base_urls" : [
    {
      # Start crawling from faz.net
      "url": "https://www.adr.gov.ro/",

      # Overwrite the default crawler and use th RecursiveCrawler instead
      "crawler": "RecursiveCrawler",

      # Because this site is weirt, use the
      # meta_contains_article_keyword-heuristic and disable all others because
      # overwrite will merge the defaults from "newscrawler.cfg" with
      # this
      "overwrite_heuristics": {
        "meta_contains_article_keyword": true,
        "og_type": false,
        "linked_headlines": false,
        "self_linked_headlines": false
      },
      # Also state that in the condition, all heuristics used in the condition
      # have to be activated in "overwrite_heuristics" (or default) as well.
      "pass_heuristics_condition": "meta_contains_article_keyword"
    }
  ]
}
